{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8b2885e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d40395c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge nos deux jeux de données\n",
    "df_test = pd.read_csv('application_test.csv')\n",
    "df = pd.read_csv('application_train.csv')\n",
    "bureau = pd.read_csv('bureau.csv')\n",
    "bureau_balance = pd.read_csv('bureau_balance.csv')\n",
    "ccb = pd.read_csv('credit_card_balance.csv')\n",
    "install_pay = pd.read_csv('installments_payments.csv')\n",
    "pos_cash = pd.read_csv('POS_CASH_balance.csv')\n",
    "prev_app = pd.read_csv('previous_application.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f7a5e",
   "metadata": {},
   "source": [
    "# Fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fea2dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding for categorical columns with get_dummies\n",
    "def one_hot_encoder(df, nan_as_category = True):\n",
    "    original_columns = list(df.columns)\n",
    "    categorical_columns = [col for col in df.columns if df[col].dtype == 'object']\n",
    "    df = pd.get_dummies(df, columns= categorical_columns, dummy_na= nan_as_category)\n",
    "    new_columns = [c for c in df.columns if c not in original_columns]\n",
    "    return df, new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc437c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remplissage des valeurs manquantes pour les aggrégations\n",
    "def data_fill_nan(data):\n",
    "    \n",
    "    for col in data.columns:\n",
    "        if 'BURO' in col:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "\n",
    "        elif 'ACTIVE' in col:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "\n",
    "        elif 'CLOSED' in col:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "\n",
    "        elif 'EXT_SOURCE' in col:\n",
    "            data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "        elif 'PREV' in col:\n",
    "            data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "        elif 'REFUSED' in col:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "\n",
    "        elif 'APPROVED' in col:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "\n",
    "        elif 'POS' in col:\n",
    "            data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "        elif 'CC' in col:\n",
    "            data[col].fillna(0, inplace=True)\n",
    "\n",
    "        elif 'INSTAL' in col:\n",
    "            data[col].fillna(data[col].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "342c96b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour les valeurs infinies\n",
    "def del_inf(data, drop=False):\n",
    "\n",
    "    print('Shape avant :', data.shape, '\\n')\n",
    "    if drop == True:\n",
    "        for col in data.columns.drop('TARGET'):\n",
    "            data[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            data[col].dropna(inplace=True)\n",
    "    else:\n",
    "        for col in data.columns:\n",
    "            data[col].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "            data[col].dropna(inplace=True)\n",
    "\n",
    "    print('Shape après :', data.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc87b635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime les avertissements nous indiquant que l'on change les valeurs de notre jeu de données d'origine\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53931ed6",
   "metadata": {},
   "source": [
    "Maintenant, nous allons réaliser un preprocessing sur tous nos jeux de données avant de les joindre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2a28b",
   "metadata": {},
   "source": [
    "## Application (1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82fd2bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "308ff856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille initiale du jeu de données : (307511, 122)\n",
      "\n",
      "Taille actuelle du jeu de données : (307511, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille initiale du jeu de données :\", df.shape)\n",
    "\n",
    "# On supprime quelques colonnes\n",
    "df_cols_drop = ['REGION_POPULATION_RELATIVE', 'DAYS_REGISTRATION','DAYS_ID_PUBLISH',\n",
    "                'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_PHONE', 'FLAG_EMAIL',\n",
    "                'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION',\n",
    "                'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY',\n",
    "                'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG',\n",
    "                'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG',\n",
    "                'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG',\n",
    "                'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE',\n",
    "                'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE',\n",
    "                'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE',\n",
    "                'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI',\n",
    "                'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI',\n",
    "                'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI',\n",
    "                'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE',\n",
    "                'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE',\n",
    "                'NAME_TYPE_SUITE', 'CNT_CHILDREN', 'AMT_GOODS_PRICE','NAME_FAMILY_STATUS', 'OWN_CAR_AGE',\n",
    "                'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START',\n",
    "                'HOUR_APPR_PROCESS_START', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n",
    "                'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE',\n",
    "                'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "                'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
    "\n",
    "# On supprime les colonnes qui ne nous intéressent pas\n",
    "df = df.drop(columns = df_cols_drop)\n",
    "df_test = df_test.drop(columns = df_cols_drop)\n",
    "\n",
    "# Taille des jeux de données après les changements\n",
    "print(\"\\nTaille actuelle du jeu de données :\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d9ea0",
   "metadata": {},
   "source": [
    "On joint directement nos jeux principaux d'entraînement et de test. Cela permet de faire le même preprocessing sur les deux jeux de données. Les jeux seront redivisés par la suite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47d071c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille Train: 307511, taille test: 48744\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille Train: {}, taille test: {}\".format(len(df), len(df_test)))\n",
    "df = df.append(df_test).reset_index()\n",
    "\n",
    "# On supprime 4 lignes où le genre n'est pas renseigné\n",
    "df = df[df['CODE_GENDER'] != 'XNA']\n",
    "\n",
    "# 3 variables sont binaires, on les change directement\n",
    "for binary_feat in ['CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']:\n",
    "    df[binary_feat], uniques = pd.factorize(df[binary_feat])\n",
    "\n",
    "# On encode nos variables catégorielles\n",
    "df, cat_cols = one_hot_encoder(df, nan_as_category=False)\n",
    "\n",
    "# On remplace les valeurs aberrantes par np.nan\n",
    "df['DAYS_EMPLOYED'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "# On crée quelques variables\n",
    "df['DAYS_EMPLOYED_PERC'] = df['DAYS_EMPLOYED'] / df['DAYS_BIRTH']\n",
    "df['INCOME_CREDIT_PERC'] = df['AMT_INCOME_TOTAL'] / df['AMT_CREDIT']\n",
    "df['INCOME_PER_PERSON'] = df['AMT_INCOME_TOTAL'] / df['CNT_FAM_MEMBERS']\n",
    "df['ANNUITY_INCOME_PERC'] = df['AMT_ANNUITY'] / df['AMT_INCOME_TOTAL']\n",
    "df['PAYMENT_RATE'] = df['AMT_ANNUITY'] / df['AMT_CREDIT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "531b948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('EXT_SOURCE_1', 0.5443016300305122),\n",
       " ('EXT_SOURCE_3', 0.19546050397051518),\n",
       " ('DAYS_EMPLOYED', 0.18146756079281182),\n",
       " ('DAYS_EMPLOYED_PERC', 0.18146756079281182),\n",
       " ('TARGET', 0.1368248790880587),\n",
       " ('EXT_SOURCE_2', 0.0018750824559088956),\n",
       " ('PAYMENT_RATE', 0.0001010523479232339),\n",
       " ('ANNUITY_INCOME_PERC', 0.0001010523479232339),\n",
       " ('AMT_ANNUITY', 0.0001010523479232339),\n",
       " ('CNT_FAM_MEMBERS', 5.61401932906855e-06),\n",
       " ('INCOME_PER_PERSON', 5.61401932906855e-06),\n",
       " ('ORGANIZATION_TYPE_Industry: type 8', 0.0),\n",
       " ('ORGANIZATION_TYPE_Industry: type 7', 0.0),\n",
       " ('ORGANIZATION_TYPE_Industry: type 1', 0.0),\n",
       " ('ORGANIZATION_TYPE_Industry: type 9', 0.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regardons les valeurs manquantes\n",
    "df_nan = df.isnull().mean()\n",
    "df_nan = df_nan.sort_values(ascending=False)\n",
    "liste_nan = []\n",
    "\n",
    "for x, y in zip(df_nan.index, df_nan):\n",
    "    liste_nan.append((x, y))\n",
    "\n",
    "liste_nan[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "44430eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remplace par la valeur médiane pour quelques variables\n",
    "cols = ['DAYS_EMPLOYED', 'DAYS_EMPLOYED_PERC', 'AMT_ANNUITY',\n",
    "        'PAYMENT_RATE', 'ANNUITY_INCOME_PERC', 'INCOME_PER_PERSON',\n",
    "        'CNT_FAM_MEMBERS']\n",
    "\n",
    "for col in cols:\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f1d8ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                  0.000000\n",
       "SK_ID_CURR             0.000000\n",
       "TARGET                 0.136825\n",
       "CODE_GENDER            0.000000\n",
       "FLAG_OWN_CAR           0.000000\n",
       "                         ...   \n",
       "DAYS_EMPLOYED_PERC     0.000000\n",
       "INCOME_CREDIT_PERC     0.000000\n",
       "INCOME_PER_PERSON      0.000000\n",
       "ANNUITY_INCOME_PERC    0.000000\n",
       "PAYMENT_RATE           0.000000\n",
       "Length: 138, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c809f077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant : (356251, 138) \n",
      "\n",
      "Shape après : (356251, 138) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enfin, on supprime les éventuelles valeurs infinies\n",
    "del_inf(df, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc5f63",
   "metadata": {},
   "source": [
    "## Bureau & bureau_balance (2/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9d9559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime quelques colonnes\n",
    "bb_cols_drop = ['CREDIT_CURRENCY', 'DAYS_CREDIT_UPDATE', 'DAYS_ENDDATE_FACT']\n",
    "bureau = bureau.drop(columns = bb_cols_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "451f3ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_CURR                      0\n",
       "SK_ID_BUREAU                    0\n",
       "CREDIT_ACTIVE                   0\n",
       "DAYS_CREDIT                     0\n",
       "CREDIT_DAY_OVERDUE              0\n",
       "DAYS_CREDIT_ENDDATE        105553\n",
       "AMT_CREDIT_MAX_OVERDUE    1124488\n",
       "CNT_CREDIT_PROLONG              0\n",
       "AMT_CREDIT_SUM                 13\n",
       "AMT_CREDIT_SUM_DEBT        257669\n",
       "AMT_CREDIT_SUM_LIMIT       591780\n",
       "AMT_CREDIT_SUM_OVERDUE          0\n",
       "CREDIT_TYPE                     0\n",
       "AMT_ANNUITY               1226791\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c77499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in bureau.columns:\n",
    "    bureau[col].fillna(bureau[col], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4401efac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_BUREAU      0\n",
       "MONTHS_BALANCE    0\n",
       "STATUS            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bureau_balance.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "df6e0a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On gère nos variables catégorielles\n",
    "bureau_balance, bb_cat = one_hot_encoder(bureau_balance, nan_as_category=False)\n",
    "bureau, bureau_cat = one_hot_encoder(bureau, nan_as_category=False)\n",
    "    \n",
    "# On fait une aggrégation sur bureau_balance et on joint avec bureau\n",
    "bb_aggregations = {'MONTHS_BALANCE': ['min', 'max', 'size']}\n",
    "\n",
    "for col in bb_cat:\n",
    "    bb_aggregations[col] = ['mean']\n",
    "\n",
    "bb_agg = bureau_balance.groupby('SK_ID_BUREAU').agg(bb_aggregations)\n",
    "bb_agg.columns = pd.Index([e[0] + \"_\" + e[1].upper() for e in bb_agg.columns.tolist()])\n",
    "bureau = bureau.join(bb_agg, how='left', on='SK_ID_BUREAU')\n",
    "bureau.drop(['SK_ID_BUREAU'], axis=1, inplace= True)\n",
    "    \n",
    "# Ce que l'on va utiliser pour l'aggrégation\n",
    "num_aggregations = {\n",
    "    'DAYS_CREDIT': ['min', 'max', 'mean', 'var'],\n",
    "    'DAYS_CREDIT_ENDDATE': ['min', 'max', 'mean'],\n",
    "    'CREDIT_DAY_OVERDUE': ['max', 'mean'],\n",
    "    'AMT_CREDIT_MAX_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_DEBT': ['max', 'mean', 'sum'],\n",
    "    'AMT_CREDIT_SUM_OVERDUE': ['mean'],\n",
    "    'AMT_CREDIT_SUM_LIMIT': ['mean', 'sum'],\n",
    "    'AMT_ANNUITY': ['max', 'mean'],\n",
    "    'CNT_CREDIT_PROLONG': ['sum'],\n",
    "    'MONTHS_BALANCE_MIN': ['min'],\n",
    "    'MONTHS_BALANCE_MAX': ['max'],\n",
    "    'MONTHS_BALANCE_SIZE': ['mean', 'sum']\n",
    "}\n",
    "\n",
    "# On prend la moyenne des variables catégorielles\n",
    "cat_aggregations = {}\n",
    "for cat in bureau_cat: cat_aggregations[cat] = ['mean']\n",
    "for cat in bb_cat: cat_aggregations[cat + \"_MEAN\"] = ['mean']\n",
    "\n",
    "# On agrège\n",
    "bureau_agg = bureau.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "bureau_agg.columns = pd.Index(['BURO_' + e[0] + \"_\" + e[1].upper() for e in bureau_agg.columns.tolist()])\n",
    "\n",
    "# On sépare en crédits actifs / crédits terminées pour les variables numériques\n",
    "active = bureau[bureau['CREDIT_ACTIVE_Active'] == 1]\n",
    "active_agg = active.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "active_agg.columns = pd.Index(['ACTIVE_' + e[0] + \"_\" + e[1].upper() for e in active_agg.columns.tolist()])\n",
    "bureau_agg = bureau_agg.join(active_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "closed = bureau[bureau['CREDIT_ACTIVE_Closed'] == 1]\n",
    "closed_agg = closed.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "closed_agg.columns = pd.Index(['CLOSED_' + e[0] + \"_\" + e[1].upper() for e in closed_agg.columns.tolist()])\n",
    "bureau_agg = bureau_agg.join(closed_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f717416b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BURO_DAYS_CREDIT_MIN                    0\n",
       "BURO_DAYS_CREDIT_MAX                    0\n",
       "BURO_DAYS_CREDIT_MEAN                   0\n",
       "BURO_DAYS_CREDIT_VAR                41520\n",
       "BURO_DAYS_CREDIT_ENDDATE_MIN         2585\n",
       "                                    ...  \n",
       "CLOSED_CNT_CREDIT_PROLONG_SUM       37886\n",
       "CLOSED_MONTHS_BALANCE_MIN_MIN      187316\n",
       "CLOSED_MONTHS_BALANCE_MAX_MAX      187316\n",
       "CLOSED_MONTHS_BALANCE_SIZE_MEAN    187316\n",
       "CLOSED_MONTHS_BALANCE_SIZE_SUM      37886\n",
       "Length: 105, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie s'il y a des valeurs manquantes\n",
    "bureau_agg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5dc0f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On s'occupe des valeurs manquantes\n",
    "data_fill_nan(bureau_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1bf27a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie\n",
    "bureau_agg.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce5da40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant : (305811, 105) \n",
      "\n",
      "Shape après : (305811, 105) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enfin, on supprime les éventuelles valeurs infinies\n",
    "del_inf(bureau_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe395c7",
   "metadata": {},
   "source": [
    "## Previous application (3/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85f6a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On supprime quelques colonnes\n",
    "prev_cols_drop = ['NAME_SELLER_INDUSTRY', 'AMT_GOODS_PRICE', 'CHANNEL_TYPE','HOUR_APPR_PROCESS_START',\n",
    "                  'NAME_TYPE_SUITE','NFLAG_LAST_APPL_IN_DAY','SELLERPLACE_AREA',\n",
    "                  'WEEKDAY_APPR_PROCESS_START']\n",
    "\n",
    "prev_app = prev_app.drop(columns = prev_cols_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "890a50b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On gère nos variables catégorielles\n",
    "prev_app, cat_cols = one_hot_encoder(prev_app, nan_as_category=False)\n",
    "\n",
    "# On remplace les valeurs aberrantes par np.nan\n",
    "prev_app['DAYS_FIRST_DRAWING'].replace(365243, np.nan, inplace= True)\n",
    "prev_app['DAYS_FIRST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "prev_app['DAYS_LAST_DUE_1ST_VERSION'].replace(365243, np.nan, inplace= True)\n",
    "prev_app['DAYS_LAST_DUE'].replace(365243, np.nan, inplace= True)\n",
    "prev_app['DAYS_TERMINATION'].replace(365243, np.nan, inplace= True)\n",
    "\n",
    "# On rajoute une variable\n",
    "prev_app['APP_CREDIT_PERC'] = prev_app['AMT_APPLICATION'] / prev_app['AMT_CREDIT']\n",
    "\n",
    "# Ce que l'on va utiliser pour l'aggrégation\n",
    "num_aggregations = {\n",
    "    'AMT_ANNUITY': ['min', 'max', 'mean'],\n",
    "    'AMT_APPLICATION': ['min', 'max', 'mean'],\n",
    "    'AMT_CREDIT': ['min', 'max', 'mean'],\n",
    "    'APP_CREDIT_PERC': ['min', 'max', 'mean', 'var'],\n",
    "    'AMT_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'RATE_DOWN_PAYMENT': ['min', 'max', 'mean'],\n",
    "    'DAYS_DECISION': ['min', 'max', 'mean'],\n",
    "    'CNT_PAYMENT': ['mean', 'sum'],\n",
    "}\n",
    "\n",
    "# On prend la moyenne des variables catégorielles\n",
    "cat_aggregations = {}\n",
    "for cat in cat_cols:\n",
    "    cat_aggregations[cat] = ['mean']\n",
    "\n",
    "# On agrège\n",
    "prev_agg = prev_app.groupby('SK_ID_CURR').agg({**num_aggregations, **cat_aggregations})\n",
    "prev_agg.columns = pd.Index(['PREV_' + e[0] + \"_\" + e[1].upper() for e in prev_agg.columns.tolist()])\n",
    "\n",
    "# On sépare en applications actives / applications closes pour les variables numériques\n",
    "approved = prev_app[prev_app['NAME_CONTRACT_STATUS_Approved'] == 1]\n",
    "approved_agg = approved.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "approved_agg.columns = pd.Index(['APPROVED_' + e[0] + \"_\" + e[1].upper() for e in approved_agg.columns.tolist()])\n",
    "prev_agg = prev_agg.join(approved_agg, how='left', on='SK_ID_CURR')\n",
    "\n",
    "refused = prev_app[prev_app['NAME_CONTRACT_STATUS_Refused'] == 1]\n",
    "refused_agg = refused.groupby('SK_ID_CURR').agg(num_aggregations)\n",
    "refused_agg.columns = pd.Index(['REFUSED_' + e[0] + \"_\" + e[1].upper() for e in refused_agg.columns.tolist()])\n",
    "prev_agg = prev_agg.join(refused_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "577100ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PREV_AMT_ANNUITY_MIN             480\n",
       "PREV_AMT_ANNUITY_MAX             480\n",
       "PREV_AMT_ANNUITY_MEAN            480\n",
       "PREV_AMT_APPLICATION_MIN           0\n",
       "PREV_AMT_APPLICATION_MAX           0\n",
       "                               ...  \n",
       "REFUSED_DAYS_DECISION_MIN     220580\n",
       "REFUSED_DAYS_DECISION_MAX     220580\n",
       "REFUSED_DAYS_DECISION_MEAN    220580\n",
       "REFUSED_CNT_PAYMENT_MEAN      230761\n",
       "REFUSED_CNT_PAYMENT_SUM       220580\n",
       "Length: 182, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie s'il y a des valeurs manquantes\n",
    "prev_agg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "058090b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On s'occupe des valeurs manquantes\n",
    "data_fill_nan(prev_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "69f512cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie\n",
    "prev_agg.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f3fcbc91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant : (338857, 182) \n",
      "\n",
      "Shape après : (338857, 182) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enfin, on supprime les éventuelles valeurs infinies\n",
    "del_inf(prev_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d1517c",
   "metadata": {},
   "source": [
    "## POS balance (4/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14c5b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On gère nos variables catégorielles\n",
    "pos_cash, cat_cols = one_hot_encoder(pos_cash, nan_as_category=False)\n",
    "\n",
    "# Ce que l'on va utiliser pour l'aggrégation\n",
    "aggregations = {\n",
    "    'MONTHS_BALANCE': ['max', 'mean', 'size'],\n",
    "    'SK_DPD': ['max', 'mean'],\n",
    "    'SK_DPD_DEF': ['max', 'mean']\n",
    "}\n",
    "\n",
    "# On prend la moyenne des variables catégorielles\n",
    "for cat in cat_cols:\n",
    "    aggregations[cat] = ['mean']\n",
    "\n",
    "# On agrège\n",
    "pos_agg = pos_cash.groupby('SK_ID_CURR').agg(aggregations)\n",
    "pos_agg.columns = pd.Index(['POS_' + e[0] + \"_\" + e[1].upper() for e in pos_agg.columns.tolist()])\n",
    "\n",
    "# On compte le nombre de compte POS\n",
    "pos_agg['POS_COUNT'] = pos_cash.groupby('SK_ID_CURR').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "813d1d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POS_MONTHS_BALANCE_MAX                                 0\n",
       "POS_MONTHS_BALANCE_MEAN                                0\n",
       "POS_MONTHS_BALANCE_SIZE                                0\n",
       "POS_SK_DPD_MAX                                         0\n",
       "POS_SK_DPD_MEAN                                        0\n",
       "POS_SK_DPD_DEF_MAX                                     0\n",
       "POS_SK_DPD_DEF_MEAN                                    0\n",
       "POS_NAME_CONTRACT_STATUS_Active_MEAN                   0\n",
       "POS_NAME_CONTRACT_STATUS_Amortized debt_MEAN           0\n",
       "POS_NAME_CONTRACT_STATUS_Approved_MEAN                 0\n",
       "POS_NAME_CONTRACT_STATUS_Canceled_MEAN                 0\n",
       "POS_NAME_CONTRACT_STATUS_Completed_MEAN                0\n",
       "POS_NAME_CONTRACT_STATUS_Demand_MEAN                   0\n",
       "POS_NAME_CONTRACT_STATUS_Returned to the store_MEAN    0\n",
       "POS_NAME_CONTRACT_STATUS_Signed_MEAN                   0\n",
       "POS_NAME_CONTRACT_STATUS_XNA_MEAN                      0\n",
       "POS_COUNT                                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie s'il y a des valeurs manquantes\n",
    "pos_agg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e428070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant : (337252, 17) \n",
      "\n",
      "Shape après : (337252, 17) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enfin, on supprime les éventuelles valeurs infinies\n",
    "del_inf(pos_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1433f8ff",
   "metadata": {},
   "source": [
    "## Installments payments (5/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8281158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_PREV                   0\n",
       "SK_ID_CURR                   0\n",
       "NUM_INSTALMENT_VERSION       0\n",
       "NUM_INSTALMENT_NUMBER        0\n",
       "DAYS_INSTALMENT              0\n",
       "DAYS_ENTRY_PAYMENT        2905\n",
       "AMT_INSTALMENT               0\n",
       "AMT_PAYMENT               2905\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie s'il y a des valeurs manquantes\n",
    "install_pay.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a3a77c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remplace par la médiane\n",
    "for col in install_pay.columns:\n",
    "    install_pay[col] = install_pay[col].fillna(install_pay[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9b338d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On gère nos variables catégorielles\n",
    "install_pay, cat_cols = one_hot_encoder(install_pay, nan_as_category=False)\n",
    "\n",
    "# On crée de nouvelles variables\n",
    "install_pay['PAYMENT_PERC'] = install_pay['AMT_PAYMENT'] / install_pay['AMT_INSTALMENT']\n",
    "install_pay['PAYMENT_DIFF'] = install_pay['AMT_INSTALMENT'] - install_pay['AMT_PAYMENT']\n",
    "\n",
    "# Et on veut des valeurs positives pour les nombres de jours de nos nouvelles variables\n",
    "install_pay['DPD'] = install_pay['DAYS_ENTRY_PAYMENT'] - install_pay['DAYS_INSTALMENT']\n",
    "install_pay['DBD'] = install_pay['DAYS_INSTALMENT'] - install_pay['DAYS_ENTRY_PAYMENT']\n",
    "install_pay['DPD'] = install_pay['DPD'].apply(lambda x: x if x > 0 else 0)\n",
    "install_pay['DBD'] = install_pay['DBD'].apply(lambda x: x if x > 0 else 0)\n",
    "\n",
    "# Ce que l'on va utiliser pour l'aggrégation\n",
    "aggregations = {\n",
    "    'NUM_INSTALMENT_VERSION': ['nunique'],\n",
    "    'DPD': ['max', 'mean', 'sum'],\n",
    "    'DBD': ['max', 'mean', 'sum'],\n",
    "    'PAYMENT_PERC': ['max', 'mean', 'sum'],\n",
    "    'PAYMENT_DIFF': ['max', 'mean', 'sum'],\n",
    "    'AMT_INSTALMENT': ['max', 'mean', 'sum'],\n",
    "    'AMT_PAYMENT': ['min', 'max', 'mean', 'sum'],\n",
    "    'DAYS_ENTRY_PAYMENT': ['max', 'mean', 'sum']\n",
    "}\n",
    "\n",
    "# On prend la moyenne des variables catégorielles\n",
    "for cat in cat_cols:\n",
    "    aggregations[cat] = ['mean']\n",
    "\n",
    "# On agrège\n",
    "ins_agg = install_pay.groupby('SK_ID_CURR').agg(aggregations)\n",
    "ins_agg.columns = pd.Index(['INSTAL_' + e[0] + \"_\" + e[1].upper() for e in ins_agg.columns.tolist()])\n",
    "\n",
    "# On compte le nombre de compte\n",
    "ins_agg['INSTAL_COUNT'] = install_pay.groupby('SK_ID_CURR').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "058e6ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INSTAL_NUM_INSTALMENT_VERSION_NUNIQUE    0\n",
       "INSTAL_DPD_MAX                           0\n",
       "INSTAL_DPD_MEAN                          0\n",
       "INSTAL_DPD_SUM                           0\n",
       "INSTAL_DBD_MAX                           0\n",
       "INSTAL_DBD_MEAN                          0\n",
       "INSTAL_DBD_SUM                           0\n",
       "INSTAL_PAYMENT_PERC_MAX                  0\n",
       "INSTAL_PAYMENT_PERC_MEAN                 0\n",
       "INSTAL_PAYMENT_PERC_SUM                  0\n",
       "INSTAL_PAYMENT_DIFF_MAX                  0\n",
       "INSTAL_PAYMENT_DIFF_MEAN                 0\n",
       "INSTAL_PAYMENT_DIFF_SUM                  0\n",
       "INSTAL_AMT_INSTALMENT_MAX                0\n",
       "INSTAL_AMT_INSTALMENT_MEAN               0\n",
       "INSTAL_AMT_INSTALMENT_SUM                0\n",
       "INSTAL_AMT_PAYMENT_MIN                   0\n",
       "INSTAL_AMT_PAYMENT_MAX                   0\n",
       "INSTAL_AMT_PAYMENT_MEAN                  0\n",
       "INSTAL_AMT_PAYMENT_SUM                   0\n",
       "INSTAL_DAYS_ENTRY_PAYMENT_MAX            0\n",
       "INSTAL_DAYS_ENTRY_PAYMENT_MEAN           0\n",
       "INSTAL_DAYS_ENTRY_PAYMENT_SUM            0\n",
       "INSTAL_COUNT                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie s'il y a des valeurs manquantes\n",
    "ins_agg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5235cabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On s'occupe des valeurs manquantes\n",
    "data_fill_nan(ins_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0259ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant : (339587, 24) \n",
      "\n",
      "Shape après : (339587, 24) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enfin, on supprime les éventuelles valeurs infinies\n",
    "del_inf(ins_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2201a6",
   "metadata": {},
   "source": [
    "## Credit card balance (6/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1af86c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SK_ID_PREV                         0\n",
       "SK_ID_CURR                         0\n",
       "MONTHS_BALANCE                     0\n",
       "AMT_BALANCE                        0\n",
       "AMT_CREDIT_LIMIT_ACTUAL            0\n",
       "AMT_DRAWINGS_ATM_CURRENT      749816\n",
       "AMT_DRAWINGS_CURRENT               0\n",
       "AMT_DRAWINGS_OTHER_CURRENT    749816\n",
       "AMT_DRAWINGS_POS_CURRENT      749816\n",
       "AMT_INST_MIN_REGULARITY       305236\n",
       "AMT_PAYMENT_CURRENT           767988\n",
       "AMT_PAYMENT_TOTAL_CURRENT          0\n",
       "AMT_RECEIVABLE_PRINCIPAL           0\n",
       "AMT_RECIVABLE                      0\n",
       "AMT_TOTAL_RECEIVABLE               0\n",
       "CNT_DRAWINGS_ATM_CURRENT      749816\n",
       "CNT_DRAWINGS_CURRENT               0\n",
       "CNT_DRAWINGS_OTHER_CURRENT    749816\n",
       "CNT_DRAWINGS_POS_CURRENT      749816\n",
       "CNT_INSTALMENT_MATURE_CUM     305236\n",
       "NAME_CONTRACT_STATUS               0\n",
       "SK_DPD                             0\n",
       "SK_DPD_DEF                         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie s'il y a des valeurs manquantes\n",
    "ccb.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16201839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On remplace par 0 les valeurs manquantes\n",
    "for col in ccb.columns:\n",
    "    ccb[col] = ccb[col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f95bf2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On gère nos variables catégorielles\n",
    "ccb, cat_cols = one_hot_encoder(ccb, nan_as_category=False)\n",
    "\n",
    "# Ce que l'on va utiliser pour l'aggrégation\n",
    "ccb.drop(['SK_ID_PREV'], axis= 1, inplace = True)\n",
    "\n",
    "# On agrège\n",
    "cc_agg = ccb.groupby('SK_ID_CURR').agg(['min', 'max', 'mean', 'sum'])\n",
    "cc_agg.columns = pd.Index(['CC_' + e[0] + \"_\" + e[1].upper() for e in cc_agg.columns.tolist()])\n",
    "\n",
    "# On compte le nombre de cartes de crédit\n",
    "cc_agg['CC_COUNT'] = ccb.groupby('SK_ID_CURR').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0ff83a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie qu'il n'y a pas de valeurs manquantes\n",
    "cc_agg.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "777de95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant : (103558, 109) \n",
      "\n",
      "Shape après : (103558, 109) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Enfin, on supprime les éventuelles valeurs infinies\n",
    "del_inf(cc_agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c590707",
   "metadata": {},
   "source": [
    "## Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fac4eb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On joint nos jeux de données\n",
    "df = df.join(bureau_agg, how='left', on='SK_ID_CURR')\n",
    "df = df.join(prev_agg, how='left', on='SK_ID_CURR')\n",
    "df = df.join(pos_agg, how='left', on='SK_ID_CURR')\n",
    "df = df.join(ins_agg, how='left', on='SK_ID_CURR')\n",
    "df = df.join(cc_agg, how='left', on='SK_ID_CURR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4041f479",
   "metadata": {},
   "source": [
    "On réalise un dernier preprocessing :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e37abf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape avant : (356251, 575) \n",
      "\n",
      "Shape après : (356251, 575) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Valeurs manquantes\n",
    "data_fill_nan(df)\n",
    "\n",
    "# Les doublons\n",
    "df.duplicated().sum()\n",
    "\n",
    "# Les valeurs infinies\n",
    "del_inf(df, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03dfb456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('TARGET', 0.1368248790880587),\n",
       " ('index', 0.0),\n",
       " ('APPROVED_APP_CREDIT_PERC_MIN', 0.0),\n",
       " ('APPROVED_AMT_APPLICATION_MIN', 0.0),\n",
       " ('APPROVED_AMT_APPLICATION_MAX', 0.0),\n",
       " ('APPROVED_AMT_APPLICATION_MEAN', 0.0),\n",
       " ('APPROVED_AMT_CREDIT_MIN', 0.0),\n",
       " ('APPROVED_AMT_CREDIT_MAX', 0.0),\n",
       " ('APPROVED_AMT_CREDIT_MEAN', 0.0),\n",
       " ('APPROVED_APP_CREDIT_PERC_MAX', 0.0),\n",
       " ('APPROVED_AMT_ANNUITY_MAX', 0.0),\n",
       " ('APPROVED_APP_CREDIT_PERC_MEAN', 0.0),\n",
       " ('APPROVED_APP_CREDIT_PERC_VAR', 0.0),\n",
       " ('APPROVED_AMT_DOWN_PAYMENT_MIN', 0.0),\n",
       " ('APPROVED_AMT_DOWN_PAYMENT_MAX', 0.0)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie qu'il n'y a pas de valeurs manquantes\n",
    "df_nan = df.isnull().mean()\n",
    "df_nan = df_nan.sort_values(ascending=False)\n",
    "liste_nan = []\n",
    "\n",
    "for x, y in zip(df_nan.index, df_nan):\n",
    "    liste_nan.append((x, y))\n",
    "\n",
    "liste_nan[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "60b61c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enregistre notre jeu de données avec le preprocessing réalisé\n",
    "df_csv = df.to_csv('data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c679f717",
   "metadata": {},
   "source": [
    "## Corrélations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747f8a9",
   "metadata": {},
   "source": [
    "On cherche à savoir les corrélations entre nos variables et notre cible (\"TARGET\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "97989e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nos corrélations :\n",
    "correlations = df.corr()['TARGET'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c13970e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corrélations positives :\n",
      "\n",
      "DAYS_BIRTH                                          0.078242\n",
      "BURO_DAYS_CREDIT_MEAN                               0.083961\n",
      "TARGET                                              1.000000\n",
      "PREV_NAME_GOODS_CATEGORY_House Construction_MEAN         NaN\n",
      "CC_SK_DPD_MIN                                            NaN\n",
      "CC_SK_DPD_DEF_MIN                                        NaN\n",
      "CC_NAME_CONTRACT_STATUS_Approved_MIN                     NaN\n",
      "CC_NAME_CONTRACT_STATUS_Demand_MIN                       NaN\n",
      "CC_NAME_CONTRACT_STATUS_Refused_MIN                      NaN\n",
      "CC_NAME_CONTRACT_STATUS_Sent proposal_MIN                NaN\n",
      "Name: TARGET, dtype: float64 \n",
      "\n",
      "\n",
      "Corrélations négatives:\n",
      "\n",
      "EXT_SOURCE_2                              -0.160295\n",
      "EXT_SOURCE_3                              -0.156026\n",
      "EXT_SOURCE_1                              -0.098875\n",
      "BURO_CREDIT_ACTIVE_Closed_MEAN            -0.076500\n",
      "PREV_CODE_REJECT_REASON_XAP_MEAN          -0.074356\n",
      "PREV_NAME_CONTRACT_STATUS_Approved_MEAN   -0.062669\n",
      "DAYS_EMPLOYED_PERC                        -0.057755\n",
      "NAME_EDUCATION_TYPE_Higher education      -0.056593\n",
      "CODE_GENDER                               -0.054710\n",
      "NAME_INCOME_TYPE_Pensioner                -0.046211\n",
      "Name: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Top 10 des corrélations positives et négatives\n",
    "print('Corrélations positives :\\n')\n",
    "print(correlations.tail(10), '\\n\\n')\n",
    "print('Corrélations négatives:\\n')\n",
    "print(correlations.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0a001d",
   "metadata": {},
   "source": [
    "Il est normal d'avoir autant de NaNs pour certaines variables, même sans avoir de valeurs manquantes dans notre jeu de données : nous n'avons quasiment pas variation dans certaines colonnes. En effet, pour certaines, nous avons remplacer beaucoup de valeurs par 0 ou par la médiane. Pour information :\n",
    "\n",
    "https://stackoverflow.com/questions/22655667/dataframe-correlation-produces-nan-although-its-values-are-all-integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16062db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
